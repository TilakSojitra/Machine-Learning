{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1noenwmBMIChUhMg85sH3xP68l9XWE8Qn",
      "authorship_tag": "ABX9TyM2T1Wlu/eYrpE80ykMQ2Go",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TilakSojitra/Machine-Learning/blob/master/ML8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementation of stacking , with max voting as classification model\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB,CategoricalNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score   \n",
        "from sklearn.metrics import precision_score   \n",
        "from sklearn.metrics import recall_score  \n",
        "\n",
        "def max_voting(output):\n",
        "  votes={}\n",
        "  for elem in output:\n",
        "    if elem in votes:\n",
        "      votes[elem]+=1\n",
        "    else :\n",
        "      votes[elem]=1\n",
        "  \n",
        "  final_output=-1\n",
        "  max_votes=-1\n",
        "  for elem in votes:\n",
        "    if max_votes<votes[elem]:\n",
        "      max_votes=votes[elem]\n",
        "      final_output=elem\n",
        "      pass\n",
        "    pass\n",
        "  print(votes)\n",
        "  return final_output,max_votes\n",
        "  pass\n",
        "\n",
        "def get_data_set():\n",
        "\n",
        "  weather = ['Sunny', 'Sunny', 'Overcast', 'Rainy', 'Rainy','Rainy', 'Overcast','Sunny', 'Sunny', 'Rainy', 'Sunny', 'Overcast', 'Overcast', 'Rainy']\n",
        "  temp = ['Hot','Hot','Hot','Mild','Cool','Cool','Cool','Mild','Cool','Mild','Mild','Mild','Hot','Mild']\n",
        "  play=['No','No','Yes','Yes','Yes','No','Yes','No','Yes','Yes','Yes','Yes','Yes','No']\n",
        "  le=preprocessing.LabelEncoder()\n",
        "  weather_encoded=le.fit_transform(weather)\n",
        "  temp_encoded=le.fit_transform(temp)\n",
        "  play_encoded=le.fit_transform(play)\n",
        "  features=tuple(zip(weather_encoded,temp_encoded))\n",
        "  return features,play_encoded\n",
        "  pass\n",
        "\n",
        "def get_individual_classifiers(x_train,y_train,no_of_models=10):\n",
        "  individual_classifiers=[]\n",
        "  for _ in range(no_of_models):\n",
        "    \n",
        "    new_model=CategoricalNB(alpha=1)\n",
        "    new_model.fit(x_train,y_train)\n",
        "    individual_classifiers.append(new_model)\n",
        "    pass\n",
        "  return individual_classifiers\n",
        "  pass\n",
        "\n",
        "def individual_predict(individual_classifiers,input):\n",
        "  output=[]\n",
        "  for classifier in individual_classifiers:\n",
        "    curr_output=list(classifier.predict(input))\n",
        "    output=output+curr_output\n",
        "    pass\n",
        "  return output\n",
        "  pass\n",
        "\n",
        "def get_meta_classifier(x,y):\n",
        "  individual_classifiers=get_individual_classifiers(x_train,y_train)\n",
        "  output=individual_predict(individual_classifiers,x)\n",
        "  meta_x=output\n",
        "  meta_y=[]\n",
        "  div=len(meta_x)//len(x)\n",
        "  for _ in range(div):\n",
        "    meta_y=meta_y+list(y)\n",
        "  meta_classifier=LogisticRegression(random_state=0).fit(x, y)\n",
        "  return meta_classifier\n",
        "  pass\n",
        "\n",
        "def get_accuracy(y_pred,y_test):\n",
        "  \n",
        "  return accuracy_score(y_pred,y_test)\n",
        "  pass\n",
        "\n",
        "\n",
        "x,y=get_data_set()\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=156,test_size=0.50)\n",
        "meta_classifier=get_meta_classifier(x_train,y_train)\n",
        "\n",
        "y_pred=meta_classifier.predict(x_test)\n",
        "print(y_pred)\n",
        "print(\"accuracy : %.3f\" % accuracy_score(y_pred,y_test))\n",
        "print(\"precision : %.3f\" % precision_score(y_pred,y_test))\n",
        "print(\"recall :  %.3f\" % recall_score(y_pred,y_test))\n",
        "# x_1,y_1=individual_predict(individual_classifiers,[[1,2]])\n",
        "# print(x_1,y_1)\n",
        "cmat=confusion_matrix(y_test,y_pred)\n",
        "print(cmat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIK1YIuamvLD",
        "outputId": "bc93a470-edc3-469a-abcb-e7b2bbb8cd82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 1 0 1]\n",
            "accuracy : 0.429\n",
            "precision : 0.333\n",
            "recall :  1.000\n",
            "[[1 0]\n",
            " [4 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# stacking using regression and low diabetes database\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB,CategoricalNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score   \n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# def max_voting(output):\n",
        "#   votes={}\n",
        "#   for elem in output:\n",
        "#     if elem in votes:\n",
        "#       votes[elem]+=1\n",
        "#     else :\n",
        "#       votes[elem]=1\n",
        "  \n",
        "#   final_output=-1\n",
        "#   max_votes=-1\n",
        "#   for elem in votes:\n",
        "#     if max_votes<votes[elem]:\n",
        "#       max_votes=votes[elem]\n",
        "#       final_output=elem\n",
        "#       pass\n",
        "#     pass\n",
        "#   print(votes)\n",
        "#   return final_output,max_votes\n",
        "#   pass\n",
        "\n",
        "def get_data_set():\n",
        "  import pandas as pd\n",
        "  dataset=load_diabetes()\n",
        "  x=dataset.data\n",
        "  y=dataset.target\n",
        "  return x,y\n",
        "  pass\n",
        "\n",
        "def get_individual_classifiers(x_train,y_train,no_of_models=10):\n",
        "  individual_classifiers=[]\n",
        "  for _ in range(no_of_models):\n",
        "    new_model=LinearRegression()\n",
        "    new_model.fit(x_train,y_train)\n",
        "    individual_classifiers.append(new_model)\n",
        "    pass\n",
        "  return individual_classifiers\n",
        "  pass\n",
        "\n",
        "def individual_predict(individual_classifiers,input):\n",
        "  output=[]\n",
        "  for classifier in individual_classifiers:\n",
        "    curr_output=list(classifier.predict(input))\n",
        "    output=output+curr_output\n",
        "    pass\n",
        "  return output\n",
        "  pass\n",
        "\n",
        "def get_meta_classifier(x,y):\n",
        "  individual_classifiers=get_individual_classifiers(x_train,y_train)\n",
        "  output=individual_predict(individual_classifiers,x)\n",
        "  meta_x=output\n",
        "  meta_y=[]\n",
        "  div=len(meta_x)//len(x)\n",
        "  for _ in range(div):\n",
        "    meta_y=meta_y+list(y)\n",
        "  meta_classifier=LinearRegression().fit(x, y)\n",
        "  return meta_classifier\n",
        "  pass\n",
        "\n",
        "def get_accuracy(y_pred,y_test):\n",
        "  return accuracy_score(y_pred,y_test)\n",
        "  pass\n",
        "\n",
        "def get_mse(y_pred,y_test):\n",
        "  return mean_squared_error(y_pred,y_test)\n",
        "  pass\n",
        "\n",
        "x,y=get_data_set()\n",
        "# print(x,y)\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=156,test_size=0.50)\n",
        "meta_classifier=get_meta_classifier(x_train,y_train)\n",
        "y_pred=meta_classifier.predict(x_test)\n",
        "print(\"mse loss : \",get_mse(y_pred,y_test))\n",
        "\n",
        "\n",
        "# x_1,y_1=individual_predict(individual_classifiers,[[1,2]])\n",
        "# print(x_1,y_1)\n",
        "\n"
      ],
      "metadata": {
        "id": "o74HxcoKh1cO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "3dc8379d-a436-4de8-b5ff-888d8b21ae4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mse loss :  3113.546774469357\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-d42fd0bff1dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mse loss : \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mget_mse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"accuracy : %.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"precision : %.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"recall :  %.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multilabel\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[1;32m     95\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous and multiclass targets"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adaboost classifier\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score   \n",
        "from sklearn.metrics import precision_score   \n",
        "from sklearn.metrics import recall_score   \n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def get_data_set():\n",
        "  import pandas as pd\n",
        "  dataset=load_breast_cancer()\n",
        "  x=dataset.data\n",
        "  y=dataset.target\n",
        "  return x,y\n",
        "  pass\n",
        "\n",
        "def get_classifier(x,y):\n",
        "  return AdaBoostClassifier().fit(x,y)\n",
        "\n",
        "def get_accuracy(y_pred,y_test):\n",
        "  return accuracy_score(y_pred,y_test)\n",
        "  pass\n",
        "\n",
        "def print_classification_report(y_pred,y_test):\n",
        "  print(\"confusion matrix of addboostclassification\")\n",
        "  cmat=confusion_matrix(y_test,y_pred)\n",
        "  print(cmat)\n",
        "  pass\n",
        "x,y=get_data_set()\n",
        "# print(x,y)\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=133,test_size=0.60)\n",
        "classifier=get_classifier(x_train,y_train)\n",
        "y_pred=classifier.predict(x_test)\n",
        "\n",
        "print(\"accuracy : %.3f\" % accuracy_score(y_pred,y_test))\n",
        "print(\"precision : %.3f\" % precision_score(y_pred,y_test))\n",
        "print(\"recall :  %.3f\" % recall_score(y_pred,y_test))\n",
        "print_classification_report(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idwGEYkbm5Z8",
        "outputId": "9b45d850-3677-447c-e35c-75da7061e2b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy : 0.936\n",
            "precision : 0.951\n",
            "recall :  0.942\n",
            "confusion matrix of addboostclassification\n",
            "[[124  10]\n",
            " [ 12 196]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use StackingClassifier from sklearn to implement the same on cancer dataset. Bagging and RandomForest\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score   \n",
        "from sklearn.metrics import precision_score   \n",
        "from sklearn.metrics import recall_score   \n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "def get_data_set():\n",
        "  import pandas as pd\n",
        "  dataset=load_breast_cancer()\n",
        "  x=dataset.data\n",
        "  y=dataset.target\n",
        "  return x,y\n",
        "  pass\n",
        "\n",
        "def get_classifier(x,y):\n",
        "  return BaggingClassifier().fit(x,y)\n",
        "\n",
        "\n",
        "def print_classification_report(y_pred,y_test):\n",
        "  print(\"confusion matrix of bagging on descision tree classifier : \")\n",
        "  cmat=confusion_matrix(y_test,y_pred)\n",
        "  print(cmat)\n",
        "  pass\n",
        "\n",
        "x,y=get_data_set()\n",
        "# print(x,y)\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=156,test_size=0.50)\n",
        "classifier=get_classifier(x_train,y_train)\n",
        "y_pred=classifier.predict(x_test)\n",
        "\n",
        "print(\"accuracy : %.3f\" % accuracy_score(y_pred,y_test))\n",
        "print(\"precision : %.3f\" % precision_score(y_pred,y_test))\n",
        "print(\"recall :  %.3f\" % recall_score(y_pred,y_test))\n",
        "\n",
        "print_classification_report(y_test,y_pred)"
      ],
      "metadata": {
        "id": "HqvGKSABiAGr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2e2f62a-85c9-46c9-a47f-f471d349ae2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy : 0.947\n",
            "precision : 0.962\n",
            "recall :  0.957\n",
            "confusion matrix of bagging on descision tree classifier : \n",
            "[[ 93   7]\n",
            " [  8 177]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Implement Adaboost Regression on concrete_data.csv.\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score   \n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "import pandas as pd\n",
        "\n",
        "cd = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Contrete.csv')\n",
        "print(cd)\n",
        "from sklearn.model_selection import train_test_split\n",
        "training_set, test_set = train_test_split(cd, test_size = 0.2, random_state = 1)\n",
        "\n",
        "X_train = training_set.iloc[:,0:8].values\n",
        "Y_train = training_set.iloc[:,8].values\n",
        "X_test = test_set.iloc[:,0:8].values\n",
        "Y_test = test_set.iloc[:,8].values\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "adaboost = AdaBoostClassifier(n_estimators=100, base_estimator= None,learning_rate=1, random_state = 1)\n",
        "adaboost.fit(X_train,Y_train)\n",
        "\n",
        "Y_pred = adaboost.predict(X_test)\n",
        "print(Y_pred)"
      ],
      "metadata": {
        "id": "Z2eX_8USiMeg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 849
        },
        "outputId": "d9a5cba1-9c27-4c6e-8eeb-1d7c925d5a15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      cement   slag  flyash  water  superplasticizer  coarseaggregate  \\\n",
            "0      540.0    0.0     0.0  162.0               2.5           1040.0   \n",
            "1      540.0    0.0     0.0  162.0               2.5           1055.0   \n",
            "2      332.5  142.5     0.0  228.0               0.0            932.0   \n",
            "3      332.5  142.5     0.0  228.0               0.0            932.0   \n",
            "4      198.6  132.4     0.0  192.0               0.0            978.4   \n",
            "...      ...    ...     ...    ...               ...              ...   \n",
            "1025   276.4  116.0    90.3  179.6               8.9            870.1   \n",
            "1026   322.2    0.0   115.6  196.0              10.4            817.9   \n",
            "1027   148.5  139.4   108.6  192.7               6.1            892.4   \n",
            "1028   159.1  186.7     0.0  175.6              11.3            989.6   \n",
            "1029   260.9  100.5    78.3  200.6               8.6            864.5   \n",
            "\n",
            "      fineaggregate  age  csMPa  \n",
            "0             676.0   28  79.99  \n",
            "1             676.0   28  61.89  \n",
            "2             594.0  270  40.27  \n",
            "3             594.0  365  41.05  \n",
            "4             825.5  360  44.30  \n",
            "...             ...  ...    ...  \n",
            "1025          768.3   28  44.28  \n",
            "1026          813.4   28  31.18  \n",
            "1027          780.0   28  23.70  \n",
            "1028          788.9   28  32.77  \n",
            "1029          761.5   28  32.40  \n",
            "\n",
            "[1030 rows x 9 columns]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-1fa7e93f54ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0madaboost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_estimator\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0madaboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madaboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0miboost\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;31m# Boosting step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             sample_weight, estimator_weight, estimator_error = self._boost(\n\u001b[0m\u001b[1;32m    146\u001b[0m                 \u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \"\"\"\n\u001b[1;32m    547\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"SAMME.R\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    935\u001b[0m         \"\"\"\n\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    938\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_classification\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;34m\"multilabel-sequences\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     ]:\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous'"
          ]
        }
      ]
    }
  ]
}